# Микросервис 023 узлы работы с системами потоковой аналитики
Система обработки потоков Kafka на базе Scala, предназначенная для потребления сообщений из различных топиков Kafka, трансформации данных и отправки обогащённых сообщений в целевые топики. Система построена с использованием Akka Streams и интегрируется с Confluent Schema Registry для сериализации Avro.
Altyn BI Kafka Streams Processing System отвечает за потребление JSON-сообщений из топиков Kafka, парсинг и трансформацию данных, а также отправку Avro-сериализованных сообщений в целевые топики. Каждый компонент Kafka Flow обрабатывает определённый тип трансформации сообщений.

Каждый компонент flow:

Потребляет JSON-сообщения из определённых топиков Kafka
Фильтрует сообщения по типу
Парсит и трансформирует данные в структурированные форматы
Сериализует данные с использованием Avro-схем
Отправляет трансформированные сообщения в целевые топики Kafka
Ключевые возможности
Обработка данных в реальном времени: Потребление и обработка JSON-сообщений из топиков Kafka в режиме реального времени
Трансформация данных: Преобразование сырых транзакционных данных в структурированные форматы с обогащённой информацией
AVRO-сериализация: Сериализация выходных данных с использованием AVRO-схемы для эффективной передачи и хранения
Обработка ошибок: Реализация надёжной обработки ошибок и стратегий супервизии для обработки потоков
Масштабируемость: Построена на Akka Streams для высокопроизводительной параллельной обработки
Поддержка множественных потоков: Поддержка нескольких независимых потоков обработки для различных типов данных
Механизм перезапуска: Реализация перезапускаемых источников с экспоненциальной задержкой для обработки временных сбоев
## Компиляция
```
sbt compile
```

## Компиляция с публикацией в локальный репозиторий
```
sbt docker:publishLocal
```

## Перенос в репозиторий altyn-i
```
docker tag altynml/altyn-bi-msv-005:latest registry.altyn-i.kz/big-data/big-data/altyn-bi-msv-005:latest
docker push registry.altyn-i.kz/big-data/big-data/altyn-bi-msv-005:latest
```
Для компиляции с последующим переносом в бой нужно явно указывать версию 
```
docker tag altynml/altyn-bi-msv-005:0.0.1 registry.altyn-i.kz/big-data/big-data/altyn-bi-msv-005:0.0.1
docker push registry.altyn-i.kz/big-data/big-data/altyn-bi-msv-005:0.0.1
```

## Запуск
```
docker-compose up -d
```

## Остановка
```
docker-compose down
```

## Логи
Все исполняемые контейнеры отправляют логи в Kafka
Для их просмотра необходимо из читать из Kafka напрямую например так:
```
ssh zookeep
kafka-console-consumer.sh --bootstrap-server broker1.hsbk.nb:9092,broker2.hsbk.nb:9092,broker3.hsbk.nb:9092 --topic altyn_bi_005_logs
```

## Перенос в бой
1. Собрать образ
2. Установить метку (docker tag)
3. Опубликовать проект в Docker репозитории altyn-i
4. На машине, на которой будет запуск в файлу docker-compose.yml прописать нужный образ, который был помечен docker tag.
5. Выполнить команды:
```shell script
docker-compose stop
docker-compose rm -f
docker-compose pull
docker-compose -f docker-compose.yml up -d
```